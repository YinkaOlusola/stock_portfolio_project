{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af137f1",
   "metadata": {},
   "source": [
    "## Technology Stocks in the S&P 500 Portfolio using Markowitz's modern portfolio theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c9470",
   "metadata": {},
   "source": [
    "The Historical dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3876fe",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e62eb",
   "metadata": {},
   "source": [
    "**The Historical stock datasets was downloaded in the form of cvs files and in the cell below, the data was read**\n",
    "\n",
    "**A much faster approach is an API call, one of which is the use of a library such as yfinance to get the stock data from Yahoo finance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all CSV files in a directory\n",
    "csv_files = glob.glob('data/*.csv')\n",
    "\n",
    "# Create an empty dataframe to store the combined data\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    file_name = str(csv_file.split('.')[0].split('\\\\')[-1])\n",
    "    updated_df = df[['Date', 'Close']]\n",
    "    updated_df[file_name] = updated_df['Close']\n",
    "    updated_df.drop(['Close'], axis=1, inplace=True)\n",
    "    updated_df['Date'] = pd.to_datetime(arg=updated_df['Date'])\n",
    "    updated_df.set_index('Date', inplace=True)\n",
    "    \n",
    "    combined_df = pd.concat([combined_df, updated_df], axis=1)\n",
    "\n",
    "    \n",
    "# While downloading the dataset, the ending dates considered for the stock was 30th of August but some\n",
    "# stocks had their end dates beyond that.The line of code was used to make the stock end dates uniform\n",
    "combined_df.drop([combined_df.index[-1], combined_df.index[-2]], inplace=True)\n",
    "\n",
    "\n",
    "# Reversing the order of the sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b963123",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "**Viewing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90563f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317234f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**The historical stock data considered was ten years, using daily data - from 01-01-2012 to 30-08-2023**\n",
    "\n",
    "**The start date for stock was 03-01-2012 as the first two days of 2012 were public holidays.**\n",
    "\n",
    "**Some Technology companies on the S&P 500 do not have their stock options extend back to 2012, and they were therfore dropped from the dataset used leaving us with 52 portfolios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping portfolios that are not up to 10 years\n",
    "\n",
    "combined_df.dropna(axis=1, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b0947",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.sort_values(['Date'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94576180",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "**Viewing the info of the dataset to ensure that the available data is consistent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617420b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e68cee",
   "metadata": {},
   "source": [
    "## Include at least one plot, particularly, a line chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef15ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171144d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a64d6a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0892531d",
   "metadata": {},
   "source": [
    "# Daily Returns for Individual Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all CSV files in a directory\n",
    "csv_files = glob.glob('data/*.csv')\n",
    "\n",
    "# Create an empty dataframe to store the combined data\n",
    "\n",
    "daily_returns = pd.DataFrame()\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    file_name = str(csv_file.split('.')[0].split('\\\\')[-1])\n",
    "    if file_name in list(combined_df.columns):\n",
    "        ind_daily_return = pd.DataFrame(combined_df[file_name].pct_change())\n",
    "        daily_returns = pd.concat([daily_returns, ind_daily_return], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1485eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns = daily_returns.sort_values(['Date'], ascending=False).mul(100)\n",
    "daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e36bf",
   "metadata": {},
   "source": [
    "# Monthly returns for individual asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f988990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all CSV files in a directory\n",
    "csv_files = glob.glob('data/*.csv')\n",
    "\n",
    "# Create an empty dataframe to store the combined data\n",
    "\n",
    "monthly_returns = pd.DataFrame()\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    file_name = str(csv_file.split('.')[0].split('\\\\')[-1])\n",
    "    if file_name in list(combined_df.columns):\n",
    "        ind_monthly_return = pd.DataFrame(combined_df[file_name].resample('M').ffill().pct_change())\n",
    "        monthly_returns = pd.concat([monthly_returns, ind_monthly_return], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_returns = monthly_returns.sort_values(['Date'], ascending=False).mul(100)\n",
    "monthly_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cede84",
   "metadata": {},
   "source": [
    "## Averages and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg = pd.DataFrame(daily_returns.mean(), columns=['Average_Daily_Return'])\n",
    "monthly_avg = pd.DataFrame(monthly_returns.mean(), columns=['Average_Monthly_Return'])\n",
    "\n",
    "\n",
    "# Variance\n",
    "daily_variance = pd.DataFrame(daily_returns.var(), columns=['Daily_Return_Variance'])\n",
    "monthly_variance = pd.DataFrame(monthly_returns.var(), columns=['Monthly_Return_Variance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = pd.concat([daily_avg, monthly_avg, daily_variance, monthly_variance], axis=1)\n",
    "\n",
    "averages['Average_Annual_Return'] = pd.DataFrame(monthly_avg.mul(12))\n",
    "\n",
    "averages['Annual_Variance'] = pd.DataFrame(monthly_variance.mul(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e732c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b4a04a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eced975",
   "metadata": {},
   "source": [
    "## Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634404a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = pd.DataFrame(daily_returns.mean(), columns=['Returns']).mul(252)\n",
    "\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = averages['Average_Annual_Return']\n",
    "\n",
    "returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e68f4",
   "metadata": {},
   "source": [
    "## Variance-Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a6352",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using the monthly returns, we compute the covariance matrix\n",
    "\n",
    "covariance = monthly_returns.cov()\n",
    "covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c3859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c47941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the monthly returns, we compute the covariance matrix\n",
    "\n",
    "covariance2 = daily_returns.cov()\n",
    "covariance2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667ecee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2fff606",
   "metadata": {},
   "source": [
    "## Equally-Weighted Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b8cbd",
   "metadata": {},
   "source": [
    "The sum of the individual weights is expected to be equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_weights(df):\n",
    "    data = []\n",
    "    weight = 1/len(list(df.columns))\n",
    "    for col in df.columns:\n",
    "        data.append([col, weight])\n",
    "    \n",
    "    weight_df = pd.DataFrame(data, columns=['Ticker', 'Weights'])\n",
    "    \n",
    "    \n",
    "    return weight_df.set_index('Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508adcac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_df = equal_weights(combined_df)\n",
    "weight_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10178d7",
   "metadata": {},
   "source": [
    "### Expected Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c38b833",
   "metadata": {},
   "source": [
    "Expected return is the product of Weights and returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef57380",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_return = weight_df.transpose().dot(returns)\n",
    "\n",
    "expected_return.values[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc02b8",
   "metadata": {},
   "source": [
    "### Expected Return in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_return_perc = expected_return['Returns'].apply('{:.2%}'.format)[0]\n",
    "\n",
    "print(expected_return_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be00b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd676760",
   "metadata": {},
   "source": [
    "## Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = weight_df.transpose().dot(covariance).dot(weight_df).apply(np.sqrt,axis=1)\n",
    "\n",
    "std_dev['Weights'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87fed6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "610ad909",
   "metadata": {},
   "source": [
    "### Sharpe Ratio\n",
    "\n",
    "**Using a Risk Free Rate of `3.00%`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b108ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate = 3.8/100.0\n",
    "\n",
    "sharpe_ratio = (expected_return['Returns'].values[0] - risk_free_rate)/std_dev['Weights'].values[0]\n",
    "\n",
    "sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50ff06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c79d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14da2699",
   "metadata": {},
   "source": [
    "### Optimal Risky Portfolio Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1570b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_weights(df):\n",
    "    data = []\n",
    "    weight = 1/len(list(df.columns))\n",
    "    for col in df.columns:\n",
    "        data.append([col, weight])\n",
    "    \n",
    "    weight_df = pd.DataFrame(data, columns=['Ticker', 'Weights'])\n",
    "    \n",
    "    \n",
    "    return weight_df.set_index('Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a0acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Optimal_weight_df = equal_weights(combined_df)\n",
    "\n",
    "Optimal_weight_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebb754",
   "metadata": {},
   "source": [
    "### Optimal Expected Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f786f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_expected_return = weight_df.transpose().dot(returns)\n",
    "\n",
    "optimal_expected_return.values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711388d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d02cfb0c",
   "metadata": {},
   "source": [
    "#### Optimal Expected Return in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb923c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_expected_return_perc = optimal_expected_return['Returns'].apply('{:.2%}'.format)[0]\n",
    "\n",
    "print(optimal_expected_return_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab7b4d",
   "metadata": {},
   "source": [
    "#### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fd2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_std_dev = weight_df.transpose().dot(covariance).dot(weight_df).apply(np.sqrt,axis=1)\n",
    "\n",
    "optimal_std_dev['Weights'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_std_dev_perc = optimal_std_dev['Weights'].apply('{:.2%}'.format)[0]\n",
    "\n",
    "print(optimal_std_dev_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fef6d9",
   "metadata": {},
   "source": [
    "### Sharpe Ratio\n",
    "\n",
    "**Using a Risk Free Rate of `3.00%`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e771e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set risk free asset rate of return\n",
    "Rf=3.8  # August 2023 average risk  free rate of return in USA approx 3.8%\n",
    "annRiskFreeRate = Rf/100\n",
    "\n",
    "#compute daily risk free rate in percentage\n",
    "risk_free_rate = (np.power((1 + annRiskFreeRate),  (1.0 / 360.0)) - 1.0) * 100 \n",
    "print('\\nRisk free rate (daily %): ', end=\"\")\n",
    "print (\"{0:.3f}\".format(risk_free_rate)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6409af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate = 3.8/100\n",
    "\n",
    "sharpe_ratio = (expected_return['Returns'].values[0] - risk_free_rate)/std_dev['Weights'].values[0]\n",
    "\n",
    "sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbeffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b2f979",
   "metadata": {},
   "source": [
    "## Sharpe Ratio based Portfolio Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1630654d",
   "metadata": {},
   "source": [
    "### The Principle of duality\n",
    "\n",
    "SInce Scipy Optimization Library only minimize, the principle of duality from optimization theory can be used to undertake transformation to obtain maximization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a143a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to undertake Sharpe Ratio maximization subject to basic constraints of the portfolio\n",
    "\n",
    "#dependencies\n",
    "\n",
    "def MaximizeSharpeRatioOptmzn(AverageReturns, VarianceCovariancce, RiskFreeRate, PortfolioSize):\n",
    "    \n",
    "    # define maximization of Sharpe Ratio using principle of duality\n",
    "    \n",
    "    def  ObjectiveFunction(weights, AverageReturns, VarianceCovariancce, RiskFreeRate, PortfolioSize):\n",
    "        Expected_Return = weights.transpose().dot(AverageReturns)\n",
    "        Standard_Deviation = np.sqrt(weights.transpose().dot(VarianceCovariancce).dot(weights))\n",
    "        funcDenom = Standard_Deviation\n",
    "        funcNumer = Expected_Return - RiskFreeRate\n",
    "        \n",
    "        func = -(funcNumer / funcDenom)\n",
    "        return func\n",
    "\n",
    "    # define equality constraint representing fully invested portfolio\n",
    "    def constraintEq(weights):\n",
    "        A=np.ones(weights.shape)\n",
    "        b=1\n",
    "        constraintVal = np.matmul(A,weights.T)-b \n",
    "        return constraintVal\n",
    "    \n",
    "    \n",
    "    #define bounds and other parameters\n",
    "    xinit=np.repeat(0.33, PortfolioSize)\n",
    "    cons = ({'type': 'eq', 'fun':constraintEq})\n",
    "    lb = 0\n",
    "    ub = 1\n",
    "    bnds = tuple([(lb,ub) for x in xinit])\n",
    "    \n",
    "    #invoke minimize solver\n",
    "    OptimizedSharpeRatio = optimize.minimize (ObjectiveFunction, x0 = xinit, args = (AverageReturns, VarianceCovariancce, \n",
    "                                                    RiskFreeRate, PortfolioSize), method = 'SLSQP', \n",
    "                                                     bounds = bnds, constraints = cons, tol = 10**-3)\n",
    "    \n",
    "    return OptimizedSharpeRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e68ac1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "portfolioSize = len(returns)\n",
    "\n",
    "sharpeRatio = MaximizeSharpeRatioOptmzn(returns, covariance, risk_free_rate, portfolioSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2717af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpeRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549551b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sharpeRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51840001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc0ae50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain maximal Sharpe Ratio for k-portfolio 1 of Dow stocks\n",
    "\n",
    "#set portfolio size\n",
    "#portfolioSize = Columns\n",
    "\n",
    "#set risk free asset rate of return\n",
    "Rf=3.8  # August 2023 average risk  free rate of return in USA approx 3.8%\n",
    "annRiskFreeRate = Rf/100\n",
    "\n",
    "#compute daily risk free rate in percentage\n",
    "risk_free_rate = (np.power((1 + annRiskFreeRate),  (1.0 / 360.0)) - 1.0) * 100 \n",
    "print('\\nRisk free rate (daily %): ', end=\"\")\n",
    "print (\"{0:.3f}\".format(risk_free_rate)) \n",
    "\n",
    "#initialization\n",
    "xOptimal =[]\n",
    "minRiskPoint = []\n",
    "expPortfolioReturnPoint =[]\n",
    "maxSharpeRatio = 0\n",
    "\n",
    "#compute maximal Sharpe Ratio and optimal weights\n",
    "result = MaximizeSharpeRatioOptmzn(returns, covariance2, risk_free_rate, portfolioSize)\n",
    "xOptimal.append(result.weights)\n",
    "\n",
    "    \n",
    "#compute risk returns and max Sharpe Ratio of the optimal portfolio   \n",
    "xOptimalArray = np.array(xOptimal)\n",
    "Risk = np.matmul((np.matmul(xOptimalArray,covReturns)), np.transpose(xOptimalArray))\n",
    "expReturn = np.matmul(np.array(meanReturns),xOptimalArray.T)\n",
    "annRisk =   np.sqrt(Risk*251) \n",
    "annRet = 251*np.array(expReturn) \n",
    "maxSharpeRatio = (annRet-Rf)/annRisk \n",
    "\n",
    "#set precision for printing results\n",
    "np.set_printoptions(precision=3, suppress = True)\n",
    "\n",
    "\n",
    "#display results\n",
    "print('Maximal Sharpe Ratio: ', maxSharpeRatio, '\\nAnnualized Risk (%):  ',\n",
    "      annRisk, '\\nAnnualized Expected Portfolio Return(%):  ', annRet)\n",
    "print('\\nOptimal weights (%):\\n',  xOptimalArray.T*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d85a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c083e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a54cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
